---
title: "CSS 205/POLI 271 Final Project"
author: "Amy Tan"
format: pdf
editor: visual
execute:
  include: true 
  warning: false
  message: false
---

```{r echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
# importing relevant libraries
library(haven)
library(tidyr)
library(reshape2)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(MASS)
library(nnet)
library(stargazer)
library(caret)


# Saving study 3 data as s3
s3 <- read_sav('original_data/Study3.sav')

# Data cleaning code provided from authors' Dataverse Rmd
s3$group= factor(s3$SKUPINA, 
                 levels = c(1,2,3,4), 
                 labels = c("Control","Equality", "Reciprocity", "Need"))
s3$SEX <- factor(s3$SEX, 
                 levels = c(1, 2), 
                 labels = c("Male","Female"))
s3$AGECAT= factor(s3$AGECAT, 
                  levels = c(1,2,3,4,5,6), 
                  labels = c("18-24","25-34","35-44", "45-54","55-64","65+"))
s3$EDU= factor(s3$EDU, 
               levels = c(1, 2,3,4), 
               labels = c("Primary","Secondary (no diploma)","Secondary (complete)", "University"))
s3$SIZE= factor(s3$SIZE, 
                levels = c(1, 2,3,4,5), 
                labels = c("less than 1k","1k-4 999","5k-19 999", "20k - 99 999","100k+"))
s3$REG= factor(s3$REG, 
               levels = c(1, 2,3,4,5,6,7,8), 
               labels = c("Bratislavsky","Trnavsky","Trenciansky", "Nitriansky","Zilinsky","Banskobystricky","Presovsky","Kosicky"))


```

## Data

Accessed from [Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/6KCW8Z).

## The Original Paper

-   Have a section about the original paper that answers the following questions:

    -   What is the unit of analysis? I.e., what are the cases in the dataset?

    -   Do you have any concerns about observational independence?

    -   What is the dependent variable for the model you are replicating?

    -   How many observations are there?

    -   How were the data sampled (an internet survey? All available cases? something else?)

    -   What do the original authors hope to achieve with the statistical model(s) you focus on? (description? prediction? causal inference?)

    -   Describe the DV. **Include a plot of the distribution of the DV** and highlight any important qualities (binary? categorical? truncated in some way? Rare? Bimodal? etc.)

    ```{r}
    s3$E3 <- as.ordered(s3$E3)

    ggplot(s3, aes(x = E3)) +
           geom_bar(fill = "gray") +
           labs(x = "Completely Disagree (1) - Completely Agree (4)", y = "Frequency") +
           theme_minimal()
    ```

    -   How did the author handle missing data?

    -   What kind of model are you replicating (logit? probit? negative binomial? etc.)

-   Demonstrate that you successfully replicated the authorsâ€™ original model. This means you will include a regression table in your paper in which the coefficient estimates, standard errors, and the number of observations are exactly the same as in the original paper.

## Original Model: Ordered Logit Model

The authors implemented a ordered logit model, with participants included as random factors, using the CLMM function. Condition (control, equality, reciprocity, need), ethnic identity (Slovak, Roma), and their interaction as predictors, and willingness to support the social housing project was the dependent variable

```{r echo=FALSE, message=FALSE, warning=FALSE, results='hide'}

# using Control as the baseline
s3$group <- relevel(s3$group, ref = 'Control')
og_ordered_logit_control <- polr(E3 ~ group, data = s3, Hess=TRUE)

# calculate in-sample performance metrics 
og_ll <- logLik(og_ordered_logit_control)
og_aic <- AIC(og_ordered_logit_control)
og_bic <- BIC(og_ordered_logit_control)

# using Reciprocity as the baseline
s3$group <- relevel(s3$group, ref = 'Reciprocity')
og_ordered_logit_recip  <- polr(E3 ~ group, data = s3, Hess=TRUE)

# regression table for replicated model
stargazer(og_ordered_logit_control, og_ordered_logit_recip,
          type = 'latex',
          column.labels = c("Base = Control", "Base = Reciprocity"),
          dep.var.labels = "DV: Personal Agreement (1-4)",
          covariate.labels = c("Control", "Equality",
                               "Reciprocity", "Need"),
          digits = 2)
```

## Alternative Models

### Ordered Logit Model with Additional Predictors

The original model only used the respondent group as a predictor. I was interested in how adding additional information

```{r echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
# reset "Control" as the reference category
s3$group <- relevel(s3$group, ref = "Control")
new_ordered_logit  <- polr(E3 ~ group + EDU + SEX + AGE, data = s3, Hess=TRUE)
summary(new_ordered_logit)

# compute in sample metrics for the new ordered logit
new_ol_ll <-logLik(new_ordered_logit)
new_ol_aic <- AIC(new_ordered_logit)
new_ol_bic <- BIC(new_ordered_logit)

# regression table for new model
stargazer(new_ordered_logit,
          type = 'latex',
          column.labels = c("Base = Control"),
          dep.var.labels = "DV: Personal Agreement (1-4)",
          covariate.labels = c("Reciprocity", "Equality", "Need",
                               "Secondary Edu (no diploma)", "Secondary Edu (complete)",
                               "University Edu", "Female"),
          digits = 2)

```

-   

-   Provide a regression table that reports the results from this new model(s).

## Comparing and Evaluating Models

-   Compare the original model and your new model(s) based on their in- and out-of-sample predictive performance. You will use cross-validation for the latter.

    ```{r echo=FALSE, message=FALSE, warning=FALSE, results='hide'}

    set.seed(12345)  # for reproducibility
    trainIndex <- createDataPartition(s3$group, p = 0.70, list = FALSE)
    s3train <- s3[trainIndex, ]
    s3test <- s3[-trainIndex, ]

    og_model_caret <- train(E3 ~ group, data = s3,
                          method = "polr",
                          trControl = trainControl(method = "none"),
                          tuneGrid = data.frame(method = "logistic"))

    new_model_caret <- train(E3 ~ group + EDU + SEX + AGE, 
                          data = s3,
                          method = "polr",
                          trControl = trainControl(method = "none"),
                          tuneGrid = data.frame(method = "logistic"))

    pred1 <- predict(og_model_caret, newdata = s3test)
    pred2 <- predict(new_model_caret, newdata = s3test)

    s3test$result <- factor(s3test$E3, levels = levels(pred1))


    # confusion matrices for out of sample performance
    og_cm <- confusionMatrix(pred1, s3test$E3)
    og_accuracy <- og_cm$overall["Accuracy"]
    new_cm <- confusionMatrix(pred2, s3test$E3)
    new_accuracy <- new_cm$overall["Accuracy"]
    ```

    ```{r echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
    stargazer(og_ordered_logit_control, new_ordered_logit,
              type = 'latex',
              dep.var.labels = "DV: Personal Agreement (1-4)",
              digits = 2,
              covariate.labels = c("Equality", "Reciprocity", "Need",
                                   "Secondary Edu (no diploma)", "Secondary Edu (complete)",
                                   "University Edu", "Female"),
              add.lines = list("In-Sample Performance",
                               c("Log Likelihood", round(og_ll, 2), round(new_ol_ll, 2)),
                               c("AIC", round(og_aic, 2), round(new_ol_aic, 2)),
                               c("BIC", round(og_bic, 2), round(new_ol_bic, 2)),
                               "Out-of-sample Performance",
                               c("Accuracy", round(og_accuracy, 2), round(new_accuracy, 2))
                               
              ))
    ```

    ## Interpreting Model 2

    ```{r}
    # scenarios - coop is the quantity of interest (1 vs. 4)
    X_female <- cbind(mean(drury$gnprat), mean(drury$trade),
                      mean(drury$tarcst), mean(drury$cost), 1)  # coop = 1, no cooperation
    X_male <- cbind(mean(drury$gnprat), mean(drury$trade), 
                       mean(drury$tarcst), mean(drury$cost), 4) # coop = 4, strong cooperation

    # coefficient vectors
    draws <- mvrnorm(1000, c(coef(order_logit1), order_logit1$zeta), 
                     solve(order_logit1$Hessian))
    Beta <- draws[, 1:length(coef(order_logit1))]
    Taus <- draws[, (length(coef(order_logit1)) + 1):ncol(draws)] 

    # predicted probabilities for "no success" category 
    pi_nosuccess_nocoop <- plogis(Taus[, 1] - Beta %*% t(X_yescoop))
    pi_nosuccess_yescoop <- plogis(Taus[, 1] - Beta %*% t(X_yescoop))  

    # predicted probabilities for "yes success" category 
    pi_yessuccess_nocoop <- 1 - plogis(Taus[, 3] - Beta %*% t(X_nocoop)) 
    pi_yessuccess_yescoop <- 1 - plogis(Taus[, 3] - Beta %*% t(X_yescoop)) 

    # differences (first differences between strong and no cooperation)
    fd_nosuccess <- pi_nosuccess_yescoop - pi_nosuccess_nocoop 
    fd_yessuccess <- pi_yessuccess_yescoop - pi_yessuccess_nocoop

    # plotting 
    df <- data.frame(
      fd_nosuccess = fd_nosuccess,
      fd_yessuccess = fd_yessuccess)

    df_long <- pivot_longer(
      df,
      cols = everything(),
      names_to = "Difference_Type",
      values_to = "Difference")

    df_long$Difference_Type <- factor(
      df_long$Difference_Type, 
      levels = c("fd_nosuccess", "fd_yessuccess"),
      labels = c("Pr(result = 1 | coop = 4) - Pr(result = 1| coop = 1)", 
                 "Pr(result = 4 | coop = 4) - Pr(result = 4 | coop = 1)"))

    ggplot(df_long, aes(x = Difference, color = Difference_Type)) +
      geom_density() +
      theme_minimal() +
      labs(
        x = "Change in Predicted Probability") +
      scale_x_continuous(limits = c(-0.8, 0.8))

    ```

-   For the best model, you will describes how a particular independent variable of your choosing relates to the dependent variable. A good paper will include a carefully described quantity of interest and present the interpretive estimate in table or graphical form that accurately incorporates our uncertainty around the estimated quantity of interest.

## Conclusion

-   Summarize your conclusions. How confident are you in the authorsâ€™ conclusions after this exercise? What more would you like to see done with this paper?

## Appendix

I used ChatGPT (<https://chatgpt.com/share/67af6953-53d0-8008-a46d-3be0d43b06fc>) to help break down the original papers' data cleaning process. It was quite helpful and helped me understand how they cleaned the filtered the raw data.

## References
